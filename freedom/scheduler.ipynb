{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9a4a7412864687a1b000066691b95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b809df877dd4be4a7bc3d01105ed89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/1.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f4c3dad1664620bb3b114bd7ff3d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ain/model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e2f3eb6eda4e508c7a1bd297aaf6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d72102e21b4214b2fb41f8bc017395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56dbe908d064b40aa0b1c2c59a3acad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ffc38a07d64d7ab9561b6936e35355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd46724014ec4a65b833c2d913d056e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_encoder/config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc38a9f27f5544e2bf9f822dfa1127ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1849ce2b3cc1486cb628d2891b75dd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410292516e6549b4a6aacc280395e086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1ac65dc40f470a8e32430453f36b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_checker/config.json:   0%|          | 0.00/4.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8534d72c7ee44344ba891f742c1b7f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20955abcf1fd415fa2c4fd1d088dc823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5b9/unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23acc0540a3472ebe68bde8290c610e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3fc879b067246a786e9f9efc7c9d1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca97f1b94594031a34692b122db6961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4146411f2a164d039b27ff70652fd218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b5b9/vae/config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fde0bfff4c4793bb930a91b48092c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "from diffusers import ControlNetModel, StableDiffusionControlNetPipeline\n",
    "# from pipeline_controlnet_freedom import StableDiffusionControlNetFreedomPipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "# controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
    "\n",
    "\n",
    "# https://huggingface.co/CrucibleAI/ControlNetMediaPipeFace\n",
    "# controlnet = ControlNetModel.from_pretrained(\"CrucibleAI/ControlNetMediaPipeFace\", subfolder=\"diffusion_sd15\")\n",
    "\n",
    "# https://huggingface.co/lllyasviel/control_v11p_sd15_openpose\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/control_v11p_sd15_openpose\", torch_dtype=torch.float16, cache_dir='/home/aiteam/tykim/hugging')\n",
    " \n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16,\n",
    "    cache_dir='/home/aiteam/tykim/hugging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict([('num_train_timesteps', 1000),\n",
       "            ('beta_start', 0.00085),\n",
       "            ('beta_end', 0.012),\n",
       "            ('beta_schedule', 'scaled_linear'),\n",
       "            ('trained_betas', None),\n",
       "            ('skip_prk_steps', True),\n",
       "            ('set_alpha_to_one', False),\n",
       "            ('prediction_type', 'epsilon'),\n",
       "            ('timestep_spacing', 'leading'),\n",
       "            ('steps_offset', 1),\n",
       "            ('_use_default_values', ['prediction_type', 'timestep_spacing']),\n",
       "            ('_class_name', 'PNDMScheduler'),\n",
       "            ('_diffusers_version', '0.6.0'),\n",
       "            ('clip_sample', False)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.scheduler.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipe.scheduler.alphas_cumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler.num_inference_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.scheduler.config.num_train_timesteps // 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_timestep = 20 - pipe.scheduler.config.num_train_timesteps // 20\n",
    "prev_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 prev_timestep = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span> - <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.num_train_timesteps // <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.num_inference_steps             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'self'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 prev_timestep = \u001b[94m10\u001b[0m - \u001b[96mself\u001b[0m.config.num_train_timesteps // \u001b[96mself\u001b[0m.num_inference_steps             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'self'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prev_timestep = 10 - self.config.num_train_timesteps // self.num_inference_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_cumprod_prev = torch.cat(\n",
    "            [torch.ones(1), pipe.scheduler.alphas_cumprod[:-1]], dim=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.scheduler.alphas_cumprod.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.ones(1), pipe.scheduler.alphas_cumprod[:-1]], dim=0).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = pipe.scheduler.alphas_cumprod\n",
    "alphas_prev = torch.cat([torch.ones(1), pipe.scheduler.alphas_cumprod[:-1]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddim_eta = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = ddim_eta * torch.sqrt((1 - alphas_prev) / (1 - alphas) * (1 - alphas / alphas_prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmas.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_one_minus_alphas = np.sqrt(1. - pipe.scheduler.alphas_cumprod) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_one_minus_alphas.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = self.sacheduler.alphas_cumprod\n",
    "alphas_prev = torch.cat([torch.ones(1), self.scheduler.alphas_cumprod[:-1]], dim=0)\n",
    "sigmas = ddim_eta * torch.sqrt((1 - alphas_cumprod_prev) / (1 - alphas_cumprod) * (1 - alphas_cumprod / alphas_cumprod_prev))\n",
    "sqrt_one_minus_alphas = np.sqrt(1. - self.scheduler.alphas_cumprod) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0292, 0.0413, 0.0506, 0.0585, 0.0655, 0.0718, 0.0777, 0.0831, 0.0883,\n",
       "        0.0932, 0.0978, 0.1023, 0.1066, 0.1107, 0.1148, 0.1186, 0.1224, 0.1261,\n",
       "        0.1297, 0.1333, 0.1367, 0.1401, 0.1434, 0.1466, 0.1498, 0.1529, 0.1560,\n",
       "        0.1591, 0.1621, 0.1650, 0.1679, 0.1708, 0.1736, 0.1764, 0.1792, 0.1820,\n",
       "        0.1847, 0.1873, 0.1900, 0.1926, 0.1952, 0.1978, 0.2004, 0.2029, 0.2054,\n",
       "        0.2079, 0.2104, 0.2128, 0.2152, 0.2177, 0.2201, 0.2224, 0.2248, 0.2271,\n",
       "        0.2295, 0.2318, 0.2341, 0.2364, 0.2387, 0.2409, 0.2432, 0.2454, 0.2476,\n",
       "        0.2498, 0.2520, 0.2542, 0.2564, 0.2586, 0.2607, 0.2629, 0.2650, 0.2671,\n",
       "        0.2692, 0.2713, 0.2734, 0.2755, 0.2776, 0.2797, 0.2817, 0.2838, 0.2858,\n",
       "        0.2879, 0.2899, 0.2919, 0.2939, 0.2959, 0.2979, 0.2999, 0.3019, 0.3039,\n",
       "        0.3059, 0.3078, 0.3098, 0.3117, 0.3137, 0.3156, 0.3176, 0.3195, 0.3214,\n",
       "        0.3233, 0.3252, 0.3271, 0.3290, 0.3309, 0.3328, 0.3347, 0.3366, 0.3385,\n",
       "        0.3403, 0.3422, 0.3440, 0.3459, 0.3478, 0.3496, 0.3514, 0.3533, 0.3551,\n",
       "        0.3569, 0.3587, 0.3606, 0.3624, 0.3642, 0.3660, 0.3678, 0.3696, 0.3714,\n",
       "        0.3732, 0.3749, 0.3767, 0.3785, 0.3803, 0.3820, 0.3838, 0.3856, 0.3873,\n",
       "        0.3891, 0.3908, 0.3926, 0.3943, 0.3961, 0.3978, 0.3995, 0.4013, 0.4030,\n",
       "        0.4047, 0.4064, 0.4081, 0.4098, 0.4115, 0.4133, 0.4150, 0.4167, 0.4183,\n",
       "        0.4200, 0.4217, 0.4234, 0.4251, 0.4268, 0.4285, 0.4301, 0.4318, 0.4335,\n",
       "        0.4351, 0.4368, 0.4384, 0.4401, 0.4418, 0.4434, 0.4451, 0.4467, 0.4483,\n",
       "        0.4500, 0.4516, 0.4532, 0.4549, 0.4565, 0.4581, 0.4597, 0.4614, 0.4630,\n",
       "        0.4646, 0.4662, 0.4678, 0.4694, 0.4710, 0.4726, 0.4742, 0.4758, 0.4774,\n",
       "        0.4790, 0.4806, 0.4822, 0.4837, 0.4853, 0.4869, 0.4885, 0.4900, 0.4916,\n",
       "        0.4932, 0.4947, 0.4963, 0.4979, 0.4994, 0.5010, 0.5025, 0.5041, 0.5056,\n",
       "        0.5071, 0.5087, 0.5102, 0.5118, 0.5133, 0.5148, 0.5163, 0.5179, 0.5194,\n",
       "        0.5209, 0.5224, 0.5239, 0.5255, 0.5270, 0.5285, 0.5300, 0.5315, 0.5330,\n",
       "        0.5345, 0.5360, 0.5375, 0.5390, 0.5405, 0.5419, 0.5434, 0.5449, 0.5464,\n",
       "        0.5479, 0.5493, 0.5508, 0.5523, 0.5537, 0.5552, 0.5567, 0.5581, 0.5596,\n",
       "        0.5610, 0.5625, 0.5639, 0.5654, 0.5668, 0.5683, 0.5697, 0.5711, 0.5726,\n",
       "        0.5740, 0.5754, 0.5769, 0.5783, 0.5797, 0.5811, 0.5826, 0.5840, 0.5854,\n",
       "        0.5868, 0.5882, 0.5896, 0.5910, 0.5924, 0.5938, 0.5952, 0.5966, 0.5980,\n",
       "        0.5994, 0.6008, 0.6022, 0.6035, 0.6049, 0.6063, 0.6077, 0.6090, 0.6104,\n",
       "        0.6118, 0.6131, 0.6145, 0.6159, 0.6172, 0.6186, 0.6199, 0.6213, 0.6226,\n",
       "        0.6240, 0.6253, 0.6267, 0.6280, 0.6293, 0.6307, 0.6320, 0.6333, 0.6346,\n",
       "        0.6360, 0.6373, 0.6386, 0.6399, 0.6412, 0.6425, 0.6439, 0.6452, 0.6465,\n",
       "        0.6478, 0.6491, 0.6504, 0.6517, 0.6529, 0.6542, 0.6555, 0.6568, 0.6581,\n",
       "        0.6594, 0.6606, 0.6619, 0.6632, 0.6644, 0.6657, 0.6670, 0.6682, 0.6695,\n",
       "        0.6707, 0.6720, 0.6733, 0.6745, 0.6757, 0.6770, 0.6782, 0.6795, 0.6807,\n",
       "        0.6819, 0.6832, 0.6844, 0.6856, 0.6868, 0.6881, 0.6893, 0.6905, 0.6917,\n",
       "        0.6929, 0.6941, 0.6953, 0.6965, 0.6977, 0.6989, 0.7001, 0.7013, 0.7025,\n",
       "        0.7037, 0.7049, 0.7061, 0.7072, 0.7084, 0.7096, 0.7108, 0.7119, 0.7131,\n",
       "        0.7143, 0.7154, 0.7166, 0.7177, 0.7189, 0.7200, 0.7212, 0.7223, 0.7235,\n",
       "        0.7246, 0.7257, 0.7269, 0.7280, 0.7291, 0.7303, 0.7314, 0.7325, 0.7336,\n",
       "        0.7347, 0.7359, 0.7370, 0.7381, 0.7392, 0.7403, 0.7414, 0.7425, 0.7436,\n",
       "        0.7447, 0.7458, 0.7468, 0.7479, 0.7490, 0.7501, 0.7512, 0.7522, 0.7533,\n",
       "        0.7544, 0.7554, 0.7565, 0.7576, 0.7586, 0.7597, 0.7607, 0.7618, 0.7628,\n",
       "        0.7639, 0.7649, 0.7660, 0.7670, 0.7680, 0.7691, 0.7701, 0.7711, 0.7721,\n",
       "        0.7732, 0.7742, 0.7752, 0.7762, 0.7772, 0.7782, 0.7792, 0.7802, 0.7812,\n",
       "        0.7822, 0.7832, 0.7842, 0.7852, 0.7862, 0.7871, 0.7881, 0.7891, 0.7901,\n",
       "        0.7910, 0.7920, 0.7930, 0.7939, 0.7949, 0.7959, 0.7968, 0.7978, 0.7987,\n",
       "        0.7997, 0.8006, 0.8015, 0.8025, 0.8034, 0.8044, 0.8053, 0.8062, 0.8071,\n",
       "        0.8081, 0.8090, 0.8099, 0.8108, 0.8117, 0.8126, 0.8135, 0.8144, 0.8153,\n",
       "        0.8162, 0.8171, 0.8180, 0.8189, 0.8198, 0.8207, 0.8216, 0.8224, 0.8233,\n",
       "        0.8242, 0.8251, 0.8259, 0.8268, 0.8277, 0.8285, 0.8294, 0.8302, 0.8311,\n",
       "        0.8319, 0.8328, 0.8336, 0.8344, 0.8353, 0.8361, 0.8370, 0.8378, 0.8386,\n",
       "        0.8394, 0.8403, 0.8411, 0.8419, 0.8427, 0.8435, 0.8443, 0.8451, 0.8459,\n",
       "        0.8467, 0.8475, 0.8483, 0.8491, 0.8499, 0.8507, 0.8515, 0.8523, 0.8530,\n",
       "        0.8538, 0.8546, 0.8553, 0.8561, 0.8569, 0.8576, 0.8584, 0.8592, 0.8599,\n",
       "        0.8607, 0.8614, 0.8622, 0.8629, 0.8636, 0.8644, 0.8651, 0.8658, 0.8666,\n",
       "        0.8673, 0.8680, 0.8688, 0.8695, 0.8702, 0.8709, 0.8716, 0.8723, 0.8730,\n",
       "        0.8737, 0.8744, 0.8751, 0.8758, 0.8765, 0.8772, 0.8779, 0.8786, 0.8793,\n",
       "        0.8799, 0.8806, 0.8813, 0.8820, 0.8826, 0.8833, 0.8840, 0.8846, 0.8853,\n",
       "        0.8859, 0.8866, 0.8873, 0.8879, 0.8885, 0.8892, 0.8898, 0.8905, 0.8911,\n",
       "        0.8917, 0.8924, 0.8930, 0.8936, 0.8942, 0.8949, 0.8955, 0.8961, 0.8967,\n",
       "        0.8973, 0.8979, 0.8985, 0.8991, 0.8997, 0.9003, 0.9009, 0.9015, 0.9021,\n",
       "        0.9027, 0.9033, 0.9039, 0.9045, 0.9050, 0.9056, 0.9062, 0.9068, 0.9073,\n",
       "        0.9079, 0.9085, 0.9090, 0.9096, 0.9101, 0.9107, 0.9112, 0.9118, 0.9123,\n",
       "        0.9129, 0.9134, 0.9140, 0.9145, 0.9150, 0.9156, 0.9161, 0.9166, 0.9171,\n",
       "        0.9177, 0.9182, 0.9187, 0.9192, 0.9197, 0.9202, 0.9207, 0.9213, 0.9218,\n",
       "        0.9223, 0.9228, 0.9233, 0.9237, 0.9242, 0.9247, 0.9252, 0.9257, 0.9262,\n",
       "        0.9267, 0.9271, 0.9276, 0.9281, 0.9286, 0.9290, 0.9295, 0.9300, 0.9304,\n",
       "        0.9309, 0.9313, 0.9318, 0.9323, 0.9327, 0.9332, 0.9336, 0.9340, 0.9345,\n",
       "        0.9349, 0.9354, 0.9358, 0.9362, 0.9367, 0.9371, 0.9375, 0.9379, 0.9384,\n",
       "        0.9388, 0.9392, 0.9396, 0.9400, 0.9405, 0.9409, 0.9413, 0.9417, 0.9421,\n",
       "        0.9425, 0.9429, 0.9433, 0.9437, 0.9441, 0.9445, 0.9448, 0.9452, 0.9456,\n",
       "        0.9460, 0.9464, 0.9468, 0.9471, 0.9475, 0.9479, 0.9483, 0.9486, 0.9490,\n",
       "        0.9494, 0.9497, 0.9501, 0.9504, 0.9508, 0.9512, 0.9515, 0.9519, 0.9522,\n",
       "        0.9526, 0.9529, 0.9532, 0.9536, 0.9539, 0.9543, 0.9546, 0.9549, 0.9553,\n",
       "        0.9556, 0.9559, 0.9562, 0.9566, 0.9569, 0.9572, 0.9575, 0.9579, 0.9582,\n",
       "        0.9585, 0.9588, 0.9591, 0.9594, 0.9597, 0.9600, 0.9603, 0.9606, 0.9609,\n",
       "        0.9612, 0.9615, 0.9618, 0.9621, 0.9624, 0.9627, 0.9630, 0.9633, 0.9635,\n",
       "        0.9638, 0.9641, 0.9644, 0.9647, 0.9649, 0.9652, 0.9655, 0.9657, 0.9660,\n",
       "        0.9663, 0.9665, 0.9668, 0.9671, 0.9673, 0.9676, 0.9678, 0.9681, 0.9684,\n",
       "        0.9686, 0.9689, 0.9691, 0.9694, 0.9696, 0.9698, 0.9701, 0.9703, 0.9706,\n",
       "        0.9708, 0.9710, 0.9713, 0.9715, 0.9717, 0.9720, 0.9722, 0.9724, 0.9727,\n",
       "        0.9729, 0.9731, 0.9733, 0.9735, 0.9738, 0.9740, 0.9742, 0.9744, 0.9746,\n",
       "        0.9748, 0.9750, 0.9753, 0.9755, 0.9757, 0.9759, 0.9761, 0.9763, 0.9765,\n",
       "        0.9767, 0.9769, 0.9771, 0.9773, 0.9775, 0.9777, 0.9778, 0.9780, 0.9782,\n",
       "        0.9784, 0.9786, 0.9788, 0.9790, 0.9791, 0.9793, 0.9795, 0.9797, 0.9799,\n",
       "        0.9800, 0.9802, 0.9804, 0.9806, 0.9807, 0.9809, 0.9811, 0.9812, 0.9814,\n",
       "        0.9816, 0.9817, 0.9819, 0.9820, 0.9822, 0.9824, 0.9825, 0.9827, 0.9828,\n",
       "        0.9830, 0.9831, 0.9833, 0.9834, 0.9836, 0.9837, 0.9839, 0.9840, 0.9842,\n",
       "        0.9843, 0.9845, 0.9846, 0.9847, 0.9849, 0.9850, 0.9852, 0.9853, 0.9854,\n",
       "        0.9856, 0.9857, 0.9858, 0.9860, 0.9861, 0.9862, 0.9864, 0.9865, 0.9866,\n",
       "        0.9867, 0.9869, 0.9870, 0.9871, 0.9872, 0.9873, 0.9875, 0.9876, 0.9877,\n",
       "        0.9878, 0.9879, 0.9881, 0.9882, 0.9883, 0.9884, 0.9885, 0.9886, 0.9887,\n",
       "        0.9888, 0.9889, 0.9890, 0.9892, 0.9893, 0.9894, 0.9895, 0.9896, 0.9897,\n",
       "        0.9898, 0.9899, 0.9900, 0.9901, 0.9902, 0.9903, 0.9904, 0.9905, 0.9906,\n",
       "        0.9906, 0.9907, 0.9908, 0.9909, 0.9910, 0.9911, 0.9912, 0.9913, 0.9914,\n",
       "        0.9915, 0.9915, 0.9916, 0.9917, 0.9918, 0.9919, 0.9920, 0.9920, 0.9921,\n",
       "        0.9922, 0.9923, 0.9924, 0.9924, 0.9925, 0.9926, 0.9927, 0.9927, 0.9928,\n",
       "        0.9929, 0.9930, 0.9930, 0.9931, 0.9932, 0.9933, 0.9933, 0.9934, 0.9935,\n",
       "        0.9935, 0.9936, 0.9937, 0.9937, 0.9938, 0.9939, 0.9939, 0.9940, 0.9941,\n",
       "        0.9941, 0.9942, 0.9943, 0.9943, 0.9944, 0.9944, 0.9945, 0.9946, 0.9946,\n",
       "        0.9947, 0.9947, 0.9948, 0.9948, 0.9949, 0.9950, 0.9950, 0.9951, 0.9951,\n",
       "        0.9952, 0.9952, 0.9953, 0.9953, 0.9954, 0.9954, 0.9955, 0.9955, 0.9956,\n",
       "        0.9956, 0.9957, 0.9957, 0.9958, 0.9958, 0.9959, 0.9959, 0.9960, 0.9960,\n",
       "        0.9961, 0.9961, 0.9961, 0.9962, 0.9962, 0.9963, 0.9963, 0.9964, 0.9964,\n",
       "        0.9964, 0.9965, 0.9965, 0.9966, 0.9966, 0.9966, 0.9967, 0.9967, 0.9967,\n",
       "        0.9968, 0.9968, 0.9969, 0.9969, 0.9969, 0.9970, 0.9970, 0.9970, 0.9971,\n",
       "        0.9971, 0.9971, 0.9972, 0.9972, 0.9972, 0.9973, 0.9973, 0.9973, 0.9974,\n",
       "        0.9974, 0.9974, 0.9975, 0.9975, 0.9975, 0.9976, 0.9976, 0.9976, 0.9976,\n",
       "        0.9977])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1. - pipe.scheduler.alphas_cumprod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0292, 0.0413, 0.0506, 0.0585, 0.0655, 0.0718, 0.0777, 0.0831, 0.0883,\n",
       "        0.0932, 0.0978, 0.1023, 0.1066, 0.1107, 0.1148, 0.1186, 0.1224, 0.1261,\n",
       "        0.1297, 0.1333, 0.1367, 0.1401, 0.1434, 0.1466, 0.1498, 0.1529, 0.1560,\n",
       "        0.1591, 0.1621, 0.1650, 0.1679, 0.1708, 0.1736, 0.1764, 0.1792, 0.1820,\n",
       "        0.1847, 0.1873, 0.1900, 0.1926, 0.1952, 0.1978, 0.2004, 0.2029, 0.2054,\n",
       "        0.2079, 0.2104, 0.2128, 0.2152, 0.2177, 0.2201, 0.2224, 0.2248, 0.2271,\n",
       "        0.2295, 0.2318, 0.2341, 0.2364, 0.2387, 0.2409, 0.2432, 0.2454, 0.2476,\n",
       "        0.2498, 0.2520, 0.2542, 0.2564, 0.2586, 0.2607, 0.2629, 0.2650, 0.2671,\n",
       "        0.2692, 0.2713, 0.2734, 0.2755, 0.2776, 0.2797, 0.2817, 0.2838, 0.2858,\n",
       "        0.2879, 0.2899, 0.2919, 0.2939, 0.2959, 0.2979, 0.2999, 0.3019, 0.3039,\n",
       "        0.3059, 0.3078, 0.3098, 0.3117, 0.3137, 0.3156, 0.3176, 0.3195, 0.3214,\n",
       "        0.3233, 0.3252, 0.3271, 0.3290, 0.3309, 0.3328, 0.3347, 0.3366, 0.3385,\n",
       "        0.3403, 0.3422, 0.3440, 0.3459, 0.3478, 0.3496, 0.3514, 0.3533, 0.3551,\n",
       "        0.3569, 0.3587, 0.3606, 0.3624, 0.3642, 0.3660, 0.3678, 0.3696, 0.3714,\n",
       "        0.3732, 0.3749, 0.3767, 0.3785, 0.3803, 0.3820, 0.3838, 0.3856, 0.3873,\n",
       "        0.3891, 0.3908, 0.3926, 0.3943, 0.3961, 0.3978, 0.3995, 0.4013, 0.4030,\n",
       "        0.4047, 0.4064, 0.4081, 0.4098, 0.4115, 0.4133, 0.4150, 0.4167, 0.4183,\n",
       "        0.4200, 0.4217, 0.4234, 0.4251, 0.4268, 0.4285, 0.4301, 0.4318, 0.4335,\n",
       "        0.4351, 0.4368, 0.4384, 0.4401, 0.4418, 0.4434, 0.4451, 0.4467, 0.4483,\n",
       "        0.4500, 0.4516, 0.4532, 0.4549, 0.4565, 0.4581, 0.4597, 0.4614, 0.4630,\n",
       "        0.4646, 0.4662, 0.4678, 0.4694, 0.4710, 0.4726, 0.4742, 0.4758, 0.4774,\n",
       "        0.4790, 0.4806, 0.4822, 0.4837, 0.4853, 0.4869, 0.4885, 0.4900, 0.4916,\n",
       "        0.4932, 0.4947, 0.4963, 0.4979, 0.4994, 0.5010, 0.5025, 0.5041, 0.5056,\n",
       "        0.5071, 0.5087, 0.5102, 0.5118, 0.5133, 0.5148, 0.5163, 0.5179, 0.5194,\n",
       "        0.5209, 0.5224, 0.5239, 0.5255, 0.5270, 0.5285, 0.5300, 0.5315, 0.5330,\n",
       "        0.5345, 0.5360, 0.5375, 0.5390, 0.5405, 0.5419, 0.5434, 0.5449, 0.5464,\n",
       "        0.5479, 0.5493, 0.5508, 0.5523, 0.5537, 0.5552, 0.5567, 0.5581, 0.5596,\n",
       "        0.5610, 0.5625, 0.5639, 0.5654, 0.5668, 0.5683, 0.5697, 0.5711, 0.5726,\n",
       "        0.5740, 0.5754, 0.5769, 0.5783, 0.5797, 0.5811, 0.5826, 0.5840, 0.5854,\n",
       "        0.5868, 0.5882, 0.5896, 0.5910, 0.5924, 0.5938, 0.5952, 0.5966, 0.5980,\n",
       "        0.5994, 0.6008, 0.6022, 0.6035, 0.6049, 0.6063, 0.6077, 0.6090, 0.6104,\n",
       "        0.6118, 0.6131, 0.6145, 0.6159, 0.6172, 0.6186, 0.6199, 0.6213, 0.6226,\n",
       "        0.6240, 0.6253, 0.6267, 0.6280, 0.6293, 0.6307, 0.6320, 0.6333, 0.6346,\n",
       "        0.6360, 0.6373, 0.6386, 0.6399, 0.6412, 0.6425, 0.6439, 0.6452, 0.6465,\n",
       "        0.6478, 0.6491, 0.6504, 0.6517, 0.6529, 0.6542, 0.6555, 0.6568, 0.6581,\n",
       "        0.6594, 0.6606, 0.6619, 0.6632, 0.6644, 0.6657, 0.6670, 0.6682, 0.6695,\n",
       "        0.6707, 0.6720, 0.6733, 0.6745, 0.6757, 0.6770, 0.6782, 0.6795, 0.6807,\n",
       "        0.6819, 0.6832, 0.6844, 0.6856, 0.6868, 0.6881, 0.6893, 0.6905, 0.6917,\n",
       "        0.6929, 0.6941, 0.6953, 0.6965, 0.6977, 0.6989, 0.7001, 0.7013, 0.7025,\n",
       "        0.7037, 0.7049, 0.7061, 0.7072, 0.7084, 0.7096, 0.7108, 0.7119, 0.7131,\n",
       "        0.7143, 0.7154, 0.7166, 0.7177, 0.7189, 0.7200, 0.7212, 0.7223, 0.7235,\n",
       "        0.7246, 0.7257, 0.7269, 0.7280, 0.7291, 0.7303, 0.7314, 0.7325, 0.7336,\n",
       "        0.7347, 0.7359, 0.7370, 0.7381, 0.7392, 0.7403, 0.7414, 0.7425, 0.7436,\n",
       "        0.7447, 0.7458, 0.7468, 0.7479, 0.7490, 0.7501, 0.7512, 0.7522, 0.7533,\n",
       "        0.7544, 0.7554, 0.7565, 0.7576, 0.7586, 0.7597, 0.7607, 0.7618, 0.7628,\n",
       "        0.7639, 0.7649, 0.7660, 0.7670, 0.7680, 0.7691, 0.7701, 0.7711, 0.7721,\n",
       "        0.7732, 0.7742, 0.7752, 0.7762, 0.7772, 0.7782, 0.7792, 0.7802, 0.7812,\n",
       "        0.7822, 0.7832, 0.7842, 0.7852, 0.7862, 0.7871, 0.7881, 0.7891, 0.7901,\n",
       "        0.7910, 0.7920, 0.7930, 0.7939, 0.7949, 0.7959, 0.7968, 0.7978, 0.7987,\n",
       "        0.7997, 0.8006, 0.8015, 0.8025, 0.8034, 0.8044, 0.8053, 0.8062, 0.8071,\n",
       "        0.8081, 0.8090, 0.8099, 0.8108, 0.8117, 0.8126, 0.8135, 0.8144, 0.8153,\n",
       "        0.8162, 0.8171, 0.8180, 0.8189, 0.8198, 0.8207, 0.8216, 0.8224, 0.8233,\n",
       "        0.8242, 0.8251, 0.8259, 0.8268, 0.8277, 0.8285, 0.8294, 0.8302, 0.8311,\n",
       "        0.8319, 0.8328, 0.8336, 0.8344, 0.8353, 0.8361, 0.8370, 0.8378, 0.8386,\n",
       "        0.8394, 0.8403, 0.8411, 0.8419, 0.8427, 0.8435, 0.8443, 0.8451, 0.8459,\n",
       "        0.8467, 0.8475, 0.8483, 0.8491, 0.8499, 0.8507, 0.8515, 0.8523, 0.8530,\n",
       "        0.8538, 0.8546, 0.8553, 0.8561, 0.8569, 0.8576, 0.8584, 0.8592, 0.8599,\n",
       "        0.8607, 0.8614, 0.8622, 0.8629, 0.8636, 0.8644, 0.8651, 0.8658, 0.8666,\n",
       "        0.8673, 0.8680, 0.8688, 0.8695, 0.8702, 0.8709, 0.8716, 0.8723, 0.8730,\n",
       "        0.8737, 0.8744, 0.8751, 0.8758, 0.8765, 0.8772, 0.8779, 0.8786, 0.8793,\n",
       "        0.8799, 0.8806, 0.8813, 0.8820, 0.8826, 0.8833, 0.8840, 0.8846, 0.8853,\n",
       "        0.8859, 0.8866, 0.8873, 0.8879, 0.8885, 0.8892, 0.8898, 0.8905, 0.8911,\n",
       "        0.8917, 0.8924, 0.8930, 0.8936, 0.8942, 0.8949, 0.8955, 0.8961, 0.8967,\n",
       "        0.8973, 0.8979, 0.8985, 0.8991, 0.8997, 0.9003, 0.9009, 0.9015, 0.9021,\n",
       "        0.9027, 0.9033, 0.9039, 0.9045, 0.9050, 0.9056, 0.9062, 0.9068, 0.9073,\n",
       "        0.9079, 0.9085, 0.9090, 0.9096, 0.9101, 0.9107, 0.9112, 0.9118, 0.9123,\n",
       "        0.9129, 0.9134, 0.9140, 0.9145, 0.9150, 0.9156, 0.9161, 0.9166, 0.9171,\n",
       "        0.9177, 0.9182, 0.9187, 0.9192, 0.9197, 0.9202, 0.9207, 0.9213, 0.9218,\n",
       "        0.9223, 0.9228, 0.9233, 0.9237, 0.9242, 0.9247, 0.9252, 0.9257, 0.9262,\n",
       "        0.9267, 0.9271, 0.9276, 0.9281, 0.9286, 0.9290, 0.9295, 0.9300, 0.9304,\n",
       "        0.9309, 0.9313, 0.9318, 0.9323, 0.9327, 0.9332, 0.9336, 0.9340, 0.9345,\n",
       "        0.9349, 0.9354, 0.9358, 0.9362, 0.9367, 0.9371, 0.9375, 0.9379, 0.9384,\n",
       "        0.9388, 0.9392, 0.9396, 0.9400, 0.9405, 0.9409, 0.9413, 0.9417, 0.9421,\n",
       "        0.9425, 0.9429, 0.9433, 0.9437, 0.9441, 0.9445, 0.9448, 0.9452, 0.9456,\n",
       "        0.9460, 0.9464, 0.9468, 0.9471, 0.9475, 0.9479, 0.9483, 0.9486, 0.9490,\n",
       "        0.9494, 0.9497, 0.9501, 0.9504, 0.9508, 0.9512, 0.9515, 0.9519, 0.9522,\n",
       "        0.9526, 0.9529, 0.9532, 0.9536, 0.9539, 0.9543, 0.9546, 0.9549, 0.9553,\n",
       "        0.9556, 0.9559, 0.9562, 0.9566, 0.9569, 0.9572, 0.9575, 0.9579, 0.9582,\n",
       "        0.9585, 0.9588, 0.9591, 0.9594, 0.9597, 0.9600, 0.9603, 0.9606, 0.9609,\n",
       "        0.9612, 0.9615, 0.9618, 0.9621, 0.9624, 0.9627, 0.9630, 0.9633, 0.9635,\n",
       "        0.9638, 0.9641, 0.9644, 0.9647, 0.9649, 0.9652, 0.9655, 0.9657, 0.9660,\n",
       "        0.9663, 0.9665, 0.9668, 0.9671, 0.9673, 0.9676, 0.9678, 0.9681, 0.9684,\n",
       "        0.9686, 0.9689, 0.9691, 0.9694, 0.9696, 0.9698, 0.9701, 0.9703, 0.9706,\n",
       "        0.9708, 0.9710, 0.9713, 0.9715, 0.9717, 0.9720, 0.9722, 0.9724, 0.9727,\n",
       "        0.9729, 0.9731, 0.9733, 0.9735, 0.9738, 0.9740, 0.9742, 0.9744, 0.9746,\n",
       "        0.9748, 0.9750, 0.9753, 0.9755, 0.9757, 0.9759, 0.9761, 0.9763, 0.9765,\n",
       "        0.9767, 0.9769, 0.9771, 0.9773, 0.9775, 0.9777, 0.9778, 0.9780, 0.9782,\n",
       "        0.9784, 0.9786, 0.9788, 0.9790, 0.9791, 0.9793, 0.9795, 0.9797, 0.9799,\n",
       "        0.9800, 0.9802, 0.9804, 0.9806, 0.9807, 0.9809, 0.9811, 0.9812, 0.9814,\n",
       "        0.9816, 0.9817, 0.9819, 0.9820, 0.9822, 0.9824, 0.9825, 0.9827, 0.9828,\n",
       "        0.9830, 0.9831, 0.9833, 0.9834, 0.9836, 0.9837, 0.9839, 0.9840, 0.9842,\n",
       "        0.9843, 0.9845, 0.9846, 0.9847, 0.9849, 0.9850, 0.9852, 0.9853, 0.9854,\n",
       "        0.9856, 0.9857, 0.9858, 0.9860, 0.9861, 0.9862, 0.9864, 0.9865, 0.9866,\n",
       "        0.9867, 0.9869, 0.9870, 0.9871, 0.9872, 0.9873, 0.9875, 0.9876, 0.9877,\n",
       "        0.9878, 0.9879, 0.9881, 0.9882, 0.9883, 0.9884, 0.9885, 0.9886, 0.9887,\n",
       "        0.9888, 0.9889, 0.9890, 0.9892, 0.9893, 0.9894, 0.9895, 0.9896, 0.9897,\n",
       "        0.9898, 0.9899, 0.9900, 0.9901, 0.9902, 0.9903, 0.9904, 0.9905, 0.9906,\n",
       "        0.9906, 0.9907, 0.9908, 0.9909, 0.9910, 0.9911, 0.9912, 0.9913, 0.9914,\n",
       "        0.9915, 0.9915, 0.9916, 0.9917, 0.9918, 0.9919, 0.9920, 0.9920, 0.9921,\n",
       "        0.9922, 0.9923, 0.9924, 0.9924, 0.9925, 0.9926, 0.9927, 0.9927, 0.9928,\n",
       "        0.9929, 0.9930, 0.9930, 0.9931, 0.9932, 0.9933, 0.9933, 0.9934, 0.9935,\n",
       "        0.9935, 0.9936, 0.9937, 0.9937, 0.9938, 0.9939, 0.9939, 0.9940, 0.9941,\n",
       "        0.9941, 0.9942, 0.9943, 0.9943, 0.9944, 0.9944, 0.9945, 0.9946, 0.9946,\n",
       "        0.9947, 0.9947, 0.9948, 0.9948, 0.9949, 0.9950, 0.9950, 0.9951, 0.9951,\n",
       "        0.9952, 0.9952, 0.9953, 0.9953, 0.9954, 0.9954, 0.9955, 0.9955, 0.9956,\n",
       "        0.9956, 0.9957, 0.9957, 0.9958, 0.9958, 0.9959, 0.9959, 0.9960, 0.9960,\n",
       "        0.9961, 0.9961, 0.9961, 0.9962, 0.9962, 0.9963, 0.9963, 0.9964, 0.9964,\n",
       "        0.9964, 0.9965, 0.9965, 0.9966, 0.9966, 0.9966, 0.9967, 0.9967, 0.9967,\n",
       "        0.9968, 0.9968, 0.9969, 0.9969, 0.9969, 0.9970, 0.9970, 0.9970, 0.9971,\n",
       "        0.9971, 0.9971, 0.9972, 0.9972, 0.9972, 0.9973, 0.9973, 0.9973, 0.9974,\n",
       "        0.9974, 0.9974, 0.9975, 0.9975, 0.9975, 0.9976, 0.9976, 0.9976, 0.9976,\n",
       "        0.9977])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "to_torch = lambda x: x.clone().detach().to(torch.float32)\n",
    "\n",
    "to_torch(np.sqrt(1. - pipe.scheduler.alphas_cumprod.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]],\n",
       "\n",
       "\n",
       "        [[[0.2763]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((32, 1, 1, 1), pipe.scheduler.alphas_cumprod[500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
