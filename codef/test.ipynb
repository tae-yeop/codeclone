{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.configuration_utils import ConfigMixin, register_to_config\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/aiteam/tykim/codeclone/codef', '/home/aiteam/miniconda3/envs/test/lib/python310.zip', '/home/aiteam/miniconda3/envs/test/lib/python3.10', '/home/aiteam/miniconda3/envs/test/lib/python3.10/lib-dynload', '', '/home/aiteam/miniconda3/envs/test/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append('/home/aiteam/tykim/diffusers_experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controlnetfr import ControlNetModelFR\n",
    "from diffusers import UNet2DConditionModel, ControlNetModel\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\", revision=None, cache_dir='/home/aiteam/tykim/hugging/models'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModelFR.from_unet(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 320, 64, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.randn(16, 3, 512, 512)\n",
    "controlnet.controlnet_cond_embedding(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 320, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.fr_in(torch.randn(16, 512)).unsqueeze(-1).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭──────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>         <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">super</span><span style=\"font-weight: bold\">()</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.__init__</span><span style=\"font-weight: bold\">(</span>in_channels: int = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>,                                                   <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                     <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">▲</span>                                                            <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">SyntaxError: </span>invalid syntax\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[91m╭──────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m\n",
       "\u001b[91m│\u001b[0m         \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.__init__\u001b[0m\u001b[1m(\u001b[0min_channels: int = \u001b[94m4\u001b[0m,                                                   \u001b[91m│\u001b[0m\n",
       "\u001b[91m│\u001b[0m                                     \u001b[1;91m▲\u001b[0m                                                            \u001b[91m│\u001b[0m\n",
       "\u001b[91m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mSyntaxError: \u001b[0minvalid syntax\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ControlNetModelFR(ControlNetModel):\n",
    "    _supports_gradient_checkpointing = True\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 4,\n",
    "        conditioning_channels: int = 3,\n",
    "        flip_sin_to_cos: bool = True,\n",
    "        freq_shift: int = 0,\n",
    "        down_block_types: Tuple[str] = (\n",
    "            \"CrossAttnDownBlock2D\",\n",
    "            \"CrossAttnDownBlock2D\",\n",
    "            \"CrossAttnDownBlock2D\",\n",
    "            \"DownBlock2D\",\n",
    "        ),\n",
    "        only_cross_attention: Union[bool, Tuple[bool]] = False,\n",
    "        block_out_channels: Tuple[int] = (320, 640, 1280, 1280),\n",
    "        layers_per_block: int = 2,\n",
    "        downsample_padding: int = 1,\n",
    "        mid_block_scale_factor: float = 1,\n",
    "        act_fn: str = \"silu\",\n",
    "        norm_num_groups: Optional[int] = 32,\n",
    "        norm_eps: float = 1e-5,\n",
    "        cross_attention_dim: int = 1280,\n",
    "        attention_head_dim: Union[int, Tuple[int]] = 8,\n",
    "        num_attention_heads: Optional[Union[int, Tuple[int]]] = None,\n",
    "        use_linear_projection: bool = False,\n",
    "        class_embed_type: Optional[str] = None,\n",
    "        num_class_embeds: Optional[int] = None,\n",
    "        upcast_attention: bool = False,\n",
    "        resnet_time_scale_shift: str = \"default\",\n",
    "        projection_class_embeddings_input_dim: Optional[int] = None,\n",
    "        controlnet_conditioning_channel_order: str = \"rgb\",\n",
    "        conditioning_embedding_out_channels: Optional[Tuple[int]] = (16, 32, 96, 256),\n",
    "        global_pool_conditions: bool = False,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_unet(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UNet2DConditionModel, ControlNetModel\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\", revision=None, cache_dir='/home/aiteam/tykim/hugging/models'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_unet(unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 64, 64])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.conv_in(torch.randn(1, 4, 64, 64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlNetConditioningEmbedding(\n",
       "  (conv_in): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (blocks): ModuleList(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (conv_out): Conv2d(256, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.controlnet_cond_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 64, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.controlnet_cond_embedding(torch.randn(1, 3, 512, 512)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = nn.Linear(512, 320)(fr_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 320, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(3, 320)\n",
    "t = t.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 64, 64])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlnet.conv_in(torch.randn(1, 4, 64, 64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 320, 64, 64])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t * controlnet.conv_in(torch.randn(1, 4, 64, 64))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet.controlnet_cond_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.reshape(3, 320, 1, 1)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법1 ) controlnet의 conditonl 인풋의 결과와 modulation 시키기\n",
    "# 방법2 ) FiLM\n",
    "# 방법3) 억지로 맞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 320, 1, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = controlnet.controlnet_cond_embedding(torch.randn(1, 3, 512, 512)) * out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 320, 64, 64])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
    "import torch\n",
    "\n",
    "controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "num_channels_latents = 4 # self.unet.config.in_channels\n",
    "latent_width = 64 # width // self.vae_scale_factor\n",
    "latent_height = 64 # height // self.vae_scale_factor\n",
    "fr_emb = torch.randn(batch_size, 512)\n",
    "latents = torch.randn(batch_size, num_channels_latents, latent_width, latent_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 64, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 32, 32])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(4, 1, kernel_size=3, stride=2, padding=1)(latents).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(512, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_emb = torch.randn(batch_size, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1024])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_emb = fr_emb.unsqueeze(1)\n",
    "out = layer1(fr_emb)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 32, 32])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "rearrange(out, \"b c (h w) -> b c h w\", h=32, w=32).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d(1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'Moduel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mFuseLayer\u001b[39;00m(nn\u001b[39m.\u001b[39;49mModuel):\n\u001b[1;32m      2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ):\n\u001b[1;32m      3\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'Moduel'"
     ]
    }
   ],
   "source": [
    "class FuseLayer(nn.Module):\n",
    "    def __init__(self, fr_emb_dim, num_channels_latents, latent_width, latent_height):\n",
    "        super().__init__()\n",
    "        self.fr_emb_dim = fr_emb_dim\n",
    "        self.num_channels_latents =  num_channels_latents\n",
    "        self.latent_width = latent_width \n",
    "        self.latent_height = latent_height\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d()\n",
    "        self.layer1 = nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1)\n",
    "        self.layer2 = nn.Conv2d(8, 1, kernel_size=3, stride=2, padding=1)\n",
    "        self.layer = nn.Linear(256 + )\n",
    "\n",
    "    def forward(self, fr_emb, latents):\n",
    "        \"\"\"\n",
    "        args:\n",
    "        returns:\n",
    "            fused_latent : [B, 4, 64, ]\n",
    "\n",
    "        \"\"\"\n",
    "        b = latents.size(0)\n",
    "        # 4, 64 64 -> 4, 32, 32\n",
    "        x = self.layer1(latents)\n",
    "        # 4, 32 32 -> 2, 16, 16\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = x.reshape(b, 2*16*16)\n",
    "\n",
    "        concat = torch.cat([x, fr_emb])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
